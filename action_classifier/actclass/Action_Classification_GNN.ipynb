{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# how action_classifier works\n",
    "\n",
    "## 1. `ac.py`:\n",
    "Dreher set the ac.py as a python external module, so that people can import the module directly.\n",
    "\n",
    "###### `sys.exit(ac.exec.main(sys.argv[1:]))`\n",
    "\n",
    "`sys.exit()` means the program exits the module onece launched the command.\n",
    "\n",
    "`sys.argv[]` means a String list, which is passed to the function.\n",
    "It returns a String of status of the executing program.\n",
    "\n",
    "## 2. exec.py\n",
    "#### 2.0 `exec.main(argv)`:\n",
    "###### `args = parse_args(argv, env)`\n",
    " this `args` contain methods and arguments. argv: methods in the module: `\n",
    "[mkevenv, train, predict, dataset, evaluate]`. For example,if `argv` is dataset, then it turns to\n",
    "`parse_args(dataset, env)`. `env` is a dictionary which contains path to the dataset.\n",
    "\n",
    "###### `code = getattr(ac.exec, args.command)(args)`:\n",
    "Get a named attribute from an object. `getattr(x, 'y')` is\n",
    "equivalent to `x.y`. `getattr(object, method)(argument of method)`: object calls the method with the given argument.\n",
    "More specifically: `ac.exec.args.command(args)`.\n",
    "\n",
    "####  2.1 `def dataset(args) -> int`:\n",
    "Generate the symbolic and graphs dataset.\n",
    "##### Arguments:\n",
    "- `--history-size`: Amount of scene graphs to be considered in the history for temporal edges; Default is 10.\n",
    "- `--raw-dataset-path`: Dataset path to the derived information. Default given in `env` variable.\n",
    "\n",
    "#####  2.1.1 `ac.dataset.generate_symbolic_dataset(args.raw_dataset_path, args.basepath)`:\n",
    "Generate symbolic dataset in a cache file from derived data and ground truth data. For each `subject`, each `task`,\n",
    "and each `take`, `rec = Recording(derived_data_path, ground_truth_path)` is called.\n",
    "Generally speaking, in the `symbolic_dataset.cache`, an object of class `Recording` of each take is saved.  <br>\n",
    "`Recording` is a class, which has some attributes like `frame_count`, `objects`, and `relations`.\n",
    "It has also some methods like `_load_objects()`, `_load_relations()`, and `_load_ground_truth()`.\n",
    "\n",
    "- `_load_objects()`: load 3d_objects derived data for each frame. Save the loaded data into `self.objects`. For each take,\n",
    "end loading when the number of loaded objects equals the number of frames of this take. An example loading path is \"derived_data_path\" +\n",
    "\"3d_objects\" + \"frame_10\".  <br>\n",
    "It is worth mentioning that the loaded object data of each frame is serialised and used as the\n",
    "input in the class `Object`. That means there are 6 variables for each loaded object in each frame. They are `certainty`,\n",
    "`class_index`, `class_name`, `instance_name`, `bounding_box`, `past_bounding_box`.  <br>\n",
    "The variables `bounding_box` and `past_bounding_box` are in object of class `BoundingBox`. It also uses serialization to\n",
    "get information from upper object.\n",
    "\n",
    "- `_load_relations()`: same idea. Class `Relation` has such attributes: `subject_index`, `object_index`, `relation_name`.\n",
    "Each frame mach has multiple dictionary to describe different relations between subject and object.\n",
    "\n",
    "- `_load_ground_truth()`: same idea. However, there are only one ground-truth file for each take instead of each frame.\n",
    "So we load directly from path instead of iterating over frames using `_load_json_series`.  <br>\n",
    "The ground-truth is in format `begin_frame -> action_index -> action_changing_frame -> action_index -> end_frame`.\n",
    "\n",
    "Summary: for each frame, an object of `Object()` and `Relation()` are saved. For each take, an object of `GroundTruth`\n",
    "is saved. All objects contains multiple attributes. For each take, the information is saved by `recs[subject][task][take] = rec`.\n",
    "Once the dataset for all subjects are loaded, the information is written into the cache file.\n",
    "\n",
    "##### 2.1.2 `ac.dataset.generate_dataset(args.basepath, dataset_config, args.history_size)`:\n",
    "load the saved cache file into a list by `recs = load_symbolic(basepath)`. It's kind of frustrating because 16 GB memory\n",
    "is enough for generating cache file but not enough for loading it into python list. Luckily, 32 GB memory is enough for the loading.  <br>\n",
    "\n",
    "###### `for subject, task, take in crawl_dataset():`\n",
    "returns a generator, which covers each subject, task, and take respectively. For each take, load the data into object\n",
    "`recording` of class `Recording`. <br>\n",
    "\n",
    "###### `recording.check_integrity()`:\n",
    "a method of class `Recording`. Firstly, it checks the size of loaded object,\n",
    "relation, and groundtruth with the frame of the take. Consequently, it checks if objects and relations match.\n",
    "\n",
    "###### `recording.to_scene_graphs(i, history_size=history_size)`:\n",
    "for each frame of the object recording (each take), take\n",
    "multiple previous scene graph for temporal edges. It returns a list, contains up to `history-size` previous scenegraphs<br>\n",
    "`i` is iterater over all frames in the take. `history_size` is a parsing argument, which indicates the amount of scene\n",
    "graphs to be considered in the history for temporal edges, the default value is 10.  <br>\n",
    "`sgl.append(self.to_scene_graph(i))`: eate a new object `sg` of class `Scenegraph` for a single frame. It contains\n",
    "attribute `left_action`, `right_action`, `nodes`, and `edges`. <br>\n",
    "Firstly it reads the groundtruth action into attribute `left_action` and `right_action`.  <br>\n",
    "Secondly it generates `nodes` of scenegraph from objects: for each object of the frame, nodes contains the index, name\n",
    "and bounding box coordinate information of the object.  <br>\n",
    "After that, it generates `edges` from relations: for each relation it generates a key consisting of (subject index,\n",
    "object index), and the value of corresponding key is a list containing all index of relation. It is worth mentioning that\n",
    "the subject index and object index are basically the node number.\n",
    "\n",
    "###### `flatten_scene_graphs(sgl)`:\n",
    "after obtaining the scenegraphs of each frame, this function flattens the multiple scengraphs\n",
    "into a single graph. Since the multiple scene graphs are the temporal previous scenegraph, we encodes the temporal relations\n",
    "of action into a single scenegraph. <br>\n",
    "Firstly it generates groundtruth for the temporal scene graph. It is directly taken from the groundtruth of the scenegraph\n",
    "of the latest frame. <br>\n",
    "Secondly it generates global `nodes`. The `global_node_id_map` is a dictionary, which has (scenegraph_id, previous_nodes_id)\n",
    " as key and an integer indicator as value. The indicater indicates the number of current nodes in all scengraphs. The nodes\n",
    " of temporal graph is the node of each seperate graph. The position of the node in the list is indicated by the value of\n",
    " dictionary. The reason of dictionary is that we can easily find the position of node of a scenegraph by their index. <br>\n",
    " Thirdly it adds the edges to the temporal scenegraph. The first step is to copy the edge from each scenegraph. The last\n",
    " step is to add edges for temporal relations. For adjacent scenegraphs, if the two nodes are same in the two scenegraphs,\n",
    " then we add a esge called `temporal`.\n",
    "\n",
    "###### `scene_graph.to_data_dict(mirrored=False)`:\n",
    "convert scenegraph of a frame into a dictionary, which has one-hot-encoding\n",
    " as value. One-hot-encoding convert a single id into one-hot-bits. `globals` contains the one-hot groundtruth action label. <br>\n",
    " For each node of the scenegraph, use one-hot to encode the object class index. `graph_nodes` contains the one-hot object class\n",
    " and the bounding box information of all objects (nodes) of the scenegraph. <br>\n",
    " For each edge of the sceengraph, use one-hot to encode the relations. It also marks the sender node and receiver node,\n",
    " not using one-hot-encoding. `graph_edges` contains the one-code relations of all edges. `graph_senders` contains sender\n",
    " node of all edges, `graph_receivers` contains all receiver nodes of all edges. <br>\n",
    " `mirrored=False` is a utility, which can generate a mirror data given input data. Therefore, the graph will have a left\n",
    " hand action and a right hand action. <br>\n",
    "\n",
    "###### `write_frame(subject, task, take, i, graphs)`:\n",
    "since we already have the graph for current frame, we can write them into\n",
    "a cache file. It generates a folder called `h10` in base path, which means the considered history frames here is 10. <br>  <br>\n",
    "Summary: The `datapath` function of the module load the `3d_objects` and `spatial_relations` derived data and saved the\n",
    "symbilc data into a cache file. After that, it loads the cache file and try to generates a temporal scene graph for each\n",
    "frame. Last it will return `STATUS_OK`, if all procedure successfully processed.\n",
    "\n",
    "#### 2.2 `def mkevenv(args) -> int`:\n",
    "Generate a environmental file, which indicates the parameters for train, prediction, and evaluation. After that, program\n",
    "needs no arguments from command line. It reads the parameters directly from evvironmental file.\n",
    "\n",
    "##### Arguments:\n",
    "- `--namespace`: String identifier of the namespace\n",
    "- `--dataset-config`: String identifier of the dataset configuration. Namely h{history_size}\n",
    "- `--evaluation-mode`: Evaluation mode, choose from (normal, contact, centroids)\n",
    "- `--processing-steps-count`: Number of processing steps the graph network should perform\n",
    "- `--layer-count` : Number of layers used for the MLPs in the graph network\n",
    "- `--neuron-count`: Number of neurons per layer used for the MLPs in the graph network\n",
    "- `--validation-id`: ID of the takes to use as validation set\n",
    "\n",
    "##### 2.2.1 `env_config = args.__dict__`:\n",
    "`__dict__` is a dictionary, which maps object to stored object’s (writable) attributes.\n",
    "\n",
    "##### 2.2.2 `json.dump(env_config, f, indent=4)`:\n",
    "write dictionary `env_config` into a jason file. The `indent` parameter that specifies how many spaces to indent. JSON array\n",
    "elements and object members will be pretty-printed with that indent level\n",
    "\n",
    "#### 2.3 `def train(args) -> int`:\n",
    "\n",
    "##### Arguments:\n",
    "- `--evaluation-id`: Numerical identifier of the left-out evaluation subject. Others for training\n",
    "- `--restore`: Iteration number of the state to restore\n",
    "- `--nax-iteration`: Maximum iteration number before interrupting. Negative values = unlimited\n",
    "- `--log-interval`: Interval in seconds after which to perform a validation\n",
    "- `--save-interval`: Number of iterations after which a model checkpoint is saveds\n",
    "\n",
    "##### 2.3.1 `train_set = ac.dataset.load(...)`:\n",
    "load graphs into training set. The loaded data are objects of class `SceneGraphProxy`.\n",
    "\n",
    "###### `paths = get_dataset_paths(datasets_basepath, dataset_config)`:\n",
    "At first it generate a list `paths`, which contains path to extracted graph for each frame.\n",
    "\n",
    "###### `SceneGraphProxy(p, evaluation_mode)`:\n",
    "for each frame, instance an object of class `SceneGraphProxy`. It contains attributes like `path`, `subject`, `task`,\n",
    "`take`, `side`, `frame`, and `mode`. It read the information from give path. Besides, it has method `load`, which allows\n",
    "it to load saved scenegraphs in `.cache` file of each frame. It is worth mentioning that the loaded information is only the\n",
    "object. That means, before it calls the method of element in dataset, there is no useful information about scenegraph loaded.\n",
    "\n",
    "###### `x for x in dataset if not filter_if(x)`:\n",
    "`filter_if(x)` is `is_ev_sub(x) or is_vld(x)`, which is true when current subject index is not evaluation id and take index\n",
    "is not validation id. When current frame is neither in evaluation id nor in validation id, we save the `sceneproxygraph`\n",
    "from current frame into a list and return it as the training set.\n",
    "\n",
    "##### 2.3.2 `train_set = ac.dataset.load(...)`:\n",
    "load graphs into validation set. It was almost same as last step but the list only contains the `scenegraphproxy` when the\n",
    "frame is from the take with validation id.\n",
    "\n",
    "##### 2.3.3 `model = ac.model.ActionClassifierModel(...)`:\n",
    "Input parameters: `out_path`, `processing_steps_count`, `layer_count`, `neuron_count` <br>\n",
    "###### `self.model = EncodeProcessDecode(...)`:\n",
    "Input parameters:\n",
    "- `layer_count`\n",
    "- `neuron_count`\n",
    "- `edge_output_size`: number of all relations\n",
    "- `node_output_size`: number of all objects\n",
    "- `global_output_size`: number of all actions\n",
    "\n",
    "Structure of `EncodeProcessDecode`:\n",
    "\n",
    "                        Hidden(t)   Hidden(t+1)\n",
    "                           |            ^\n",
    "              *---------*  |  *------*  |  *---------*\n",
    "              |         |  |  |      |  |  |         |\n",
    "    Input --->| Encoder |  *->| Core |--*->| Decoder |---> Output(t)\n",
    "              |         |---->|      |     |         |\n",
    "              *---------*     *------*     *---------*\n",
    "\n",
    "- Encoder: encodes edge, node, global attributes independently, without computation <br>\n",
    "- Core:  performs N processing / message passing steps <br>\n",
    "- Decoder: decodes edge, node, global attributes of message passing step\n",
    "\n",
    "Multilayer Perceptrons are employed as edge update functions, node update functions, and global update functions. <br>\n",
    "- `edge_fn = snt.layer(outputsize, name)`: build the linear layers. It only needs the output dimensionality\n",
    "and module name, doesn't need input dimensionality. <br>\n",
    "- `gn.modules.GraphIndependent(edge_fn, node_fn, global_fn)`: A graph block that applies models to the graph elements\n",
    "independently. The inputs and outputs are graphs. The corresponding models are applied to each element of the graph\n",
    "(edges, nodes and globals) in parallel and independently of the other elements. It can be used to encode or\n",
    "decode the elements of a graph. When it is called, the input is a `graphs.GraphsTuple` containing non-`None` edges, nodes and\n",
    "globals, and it returns an output `graphs.GraphsTuple` with updated edges, nodes and globals.<br>\n",
    "\n",
    "Build module step of `EncodeProcessDecode`:\n",
    "- Flow: `input_op` -> `encoder` -> `core` * `num_processing_steps` -> `decoder`, each input/output is graph\n",
    "- Encoder: use MLP as `edge_model_fn`, `node_model_fn`, `global_model_fn`. Pass the model function into  `GraphIndependent`.\n",
    " The input of Encoder is `input_op`.\n",
    "- Core: same model function. The input of core of each processing step is concatenated graphs of last processing step.\n",
    "- Decoder: for the output graph of core of each processing step, use `MLPGraphIndependent` (MLP) to update once and use\n",
    "`GraphIndependent` (linear) to generate the output graph for the processing step. It returns a list containing the output\n",
    "graphs of all processing steps.\n",
    "\n",
    "Summary of `EncodeProcessDecode`: Input is a graph and output is updated graphs of each processing step. It uses MLPs and\n",
    "linear layers as update function. The probability distribution of all actions is encoded in the updated global attribute `u'`.\n",
    "\n",
    "##### 2.3.4 `model.train(...)`:\n",
    "Input parameters:\n",
    "- `train_set`: Training set, list of loaded scenegraphs\n",
    "- `valid_set`: Validation set, list of loaded scenegraphs\n",
    "- `restore`: Iteration number of the state to restore\n",
    "- `batch_size_train`: Train batch size\n",
    "- `batch_size_train`: Train batch size\n",
    "- `learning_rate`: Learning rate\n",
    "- `max_iteration`: Max iteration, aborting afterwards\n",
    "- `log_interval`: Interval when a log should be printed to stdout\n",
    "- `save_interval`: Interval when the model should be saved to disk\n",
    "\n",
    "The steps in training:\n",
    "- `placeholder = [train_set[0].load()]`: set a placeholder. It calls `load` method and then the scenegraph is loaded.\n",
    "- The graph neural network in `graph_nets` has specific input structure. It converts an prepocessed graph to a GNN graph\n",
    "by function `gn.utils_tf.placeholders_from_data_dicts(graph_pre)`.\n",
    "- `optimizer = tf.train.AdamOptimizer(learning_rate)`: set Adam optimizer with given learning rate.\n",
    "- `_make_all_runnable_in_session()`: Input is graph and output is graph which is runable in tensorflow. Allows a graph\n",
    "containing `None` fields to be run in a `tf.Session`.\n",
    "- `_create_train_feed_dict`: For each iteration step, we need to create placeholders from scenegraphs. Inputs are a list\n",
    "containing loaded scenegraph, the number of scenegraphs is batch size. We drop the 2/3 `idel` and `hold` scenegraphs in\n",
    "current batch because they possesses too many frames. We also filter out the scenegraphs which has no edges.\n",
    "Finally, it retuns a dictionay `feed_dict`, which contains `input` and `target` for the curent batch. The only difference\n",
    "between `Input` and `target` is that `Input` has no action Id, it is used as feature. `target` has action id, it is used\n",
    "as labels. It is a supervised learning set.\n",
    "- `run_parameters`: contains `step`, `targets`, `loss`, and `output`.\n",
    "- `tf.session.run()`:  In a TensorFlow Session `tf.Session`, you want to run (or execute) the optimizer operation (in\n",
    "this case it is `train_step`). The optimizer minimizes your loss function (in this case cross_entropy), which is evaluated\n",
    " or computed using the model hypothesis y.\n",
    "\n",
    "\n",
    "\n",
    "#### 2.4 `def predict(args) -> int`:\n",
    "\n",
    "##### Arguments:\n",
    "- `basepath`:\n",
    "- `verbose`:\n",
    "- `namespace`:\n",
    "- `e`: use the subject which is left out in training process\n",
    "- `restore`: restore the model at which iteration; Usually set this to maximal iteration number 3000"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}